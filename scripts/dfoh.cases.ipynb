{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "base_url = \"http://dfoh.uclouvain.be/database/cases/\"\n",
    "dfoh_cases = \"/home/savymik/Pictures/dfoh_cases\"\n",
    "os.makedirs(dfoh_cases, exist_ok=True)\n",
    "\n",
    "def get_filelink():\n",
    "    response = requests.get(base_url)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Failed!, status code {response.status_code}\")\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    links = [a['href'] for a in soup.find_all('a', href=True)]\n",
    "    valid_cases = [link for link in links if link and not link.endswith('.tmp') and '/cases/' in link]\n",
    "    valid_cases = [base_url + link.split(\"/cases/\")[-1] for link in valid_cases]\n",
    "    return valid_cases\n",
    "  \n",
    "def cases_downloads():\n",
    "    cases_links = get_filelink()\n",
    "    for case_url in cases_links:\n",
    "        fname = case_url.split(\"/\")[-1]\n",
    "        fpath = os.path.join(dfoh_cases, fname)\n",
    "        if os.path.exists(fpath):\n",
    "            print(f\"File exists! Skipping: {fname}\")\n",
    "            continue\n",
    "        # print(f\"Downloading: {fname}\")\n",
    "        response = requests.get(case_url, stream=True)\n",
    "        if response.status_code == 200:\n",
    "            with open(fpath, 'wb') as f:\n",
    "                for chunk in response.iter_content(1024):\n",
    "                    f.write(chunk)\n",
    "            # print(f\"Downloaded: {fname}\")\n",
    "        else:\n",
    "            print(f\"Failed to download {case_url}, status code {response.status_code}\")\n",
    "\n",
    "def parse_dfoh_cases():\n",
    "    for fname in os.listdir(dfoh_cases):\n",
    "        fpath = os.path.join(dfoh_cases, fname)\n",
    "        if not os.path.isfile(fpath):\n",
    "            continue\n",
    "        # print(f\"Processing: {fname}\")\n",
    "        df = parse_dfoh_file(fpath)\n",
    "        if df.empty:\n",
    "            print(f\"No valid data extracted for: {fname}, skip saving!\")\n",
    "            continue\n",
    "        csv_fname = os.path.join(dfoh_cases, fname + \".csv\")\n",
    "        df.to_csv(csv_fname, index=False)\n",
    "        # print(f\"Saved: {csv_fname}\")\n",
    "\n",
    "def parse_dfoh_file(fpath):\n",
    "    if not os.path.exists(fpath):\n",
    "        print(f\"File does not exist: {fpath}, skip parsing!\")\n",
    "        return pd.DataFrame()\n",
    "    date = os.path.basename(fpath)[:10]\n",
    "    cases = []\n",
    "    with open(fpath, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    status = None\n",
    "    attacker = None\n",
    "    victim = None\n",
    "    additional_attributes = {}\n",
    "    \n",
    "    for line in lines:\n",
    "        parts = line.strip().split()\n",
    "        if not parts:\n",
    "            continue \n",
    "        if line.startswith(\"!leg\") or line.startswith(\"!sus\"):\n",
    "            status = \"leg\" if line.startswith(\"!leg\") else \"sus\"\n",
    "            if len(parts) < 6:\n",
    "                print(f\"Incomplete line: {line.strip()}, skipping!\")\n",
    "                continue\n",
    "            attacker, victim = parts[1], parts[2]\n",
    "            leg_count, sus_count, path_count = map(int, parts[3:6])\n",
    "            metadata_parts = line.split(\"attackers:\")[-1].strip().split(\";\")\n",
    "            additional_attributes = {k: v for k, v in (x.split(\":\") for x in metadata_parts if \":\" in x)}\n",
    "        else:\n",
    "            if len(parts) < 5:\n",
    "                print(f\"Incomplete inference line: {line.strip()}, skipping!\")\n",
    "                continue\n",
    "            try:\n",
    "                inference_id, leg_flag, sus_flag = map(int, parts[2:5])\n",
    "            except ValueError:\n",
    "                print(f\"Non-int inference line: {line.strip()}, skipping!\")\n",
    "                continue\n",
    "            cases.append({\"date\": date,\"status\": status,\"attacker\": attacker,\"victim\": victim,\"leg_infrence_cnts\": leg_count,\"sus_infrence_cnts\": sus_count,\n",
    "                            \"path_cnts\": path_count,\"type\": additional_attributes.get(\"type\", \"unknown\"),\"valid_origin\": additional_attributes.get(\"valid_origin\", \"unknown\"),\n",
    "                            \"recurrent\": additional_attributes.get(\"recurrent\", \"unknown\"),\"local\": additional_attributes.get(\"local\", \"unknown\"),\"inference_id\": inference_id,\"leg_flag\": leg_flag,\"sus_flag\": sus_flag\n",
    "                            })\n",
    "    return pd.DataFrame(cases)\n",
    "\n",
    "def main():\n",
    "    cases_downloads()\n",
    "    parse_dfoh_cases()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
